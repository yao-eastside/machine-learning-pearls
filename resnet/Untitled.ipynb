{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/shaojun/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.models.resnet.ResNet"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.4535e-02, -1.4596e+00, -1.1330e+00, -1.6520e+00, -2.8367e+00,\n",
      "         2.5034e-01, -1.0562e+00,  3.0290e+00,  4.8499e+00,  1.4322e-01,\n",
      "        -3.0074e+00, -1.2253e+00, -1.7812e+00, -2.6095e+00, -2.7430e+00,\n",
      "        -1.6470e+00, -6.3208e-01,  1.2096e+00, -1.2136e-01, -1.0899e+00,\n",
      "        -2.0130e+00, -6.3550e-01, -5.5107e-01,  1.1292e+00, -1.7935e+00,\n",
      "        -4.5523e-01, -6.1320e-01, -6.3687e-01, -1.0281e+00,  1.1140e+00,\n",
      "        -1.1821e+00, -9.3301e-01, -6.6413e-01, -2.8717e+00, -2.2734e+00,\n",
      "        -1.1740e+00, -1.2014e+00, -1.5959e+00, -2.8250e+00, -5.8934e-01,\n",
      "        -3.9307e-01, -2.6001e+00, -1.5767e+00, -2.5568e+00,  5.8025e-01,\n",
      "        -2.1373e+00, -5.2948e-01, -1.5152e+00, -2.4959e+00, -1.1388e+00,\n",
      "         1.6644e-01, -4.5050e-01,  1.6418e-01,  2.7722e-01, -1.1867e+00,\n",
      "        -9.4941e-01, -1.2710e+00, -9.4497e-01, -5.2795e-01, -5.3808e-01,\n",
      "         1.5079e+00, -1.5966e+00, -2.4035e+00, -1.5511e+00, -3.0469e+00,\n",
      "        -2.0768e+00, -9.0381e-01, -9.8416e-01, -1.1183e+00, -4.4446e+00,\n",
      "        -9.1346e-01,  2.0901e-01, -9.2836e-01, -1.3642e+00,  1.9494e-01,\n",
      "        -1.9500e+00, -1.6371e+00, -2.8247e-01,  1.1704e+00, -6.6096e-01,\n",
      "        -1.3871e+00, -1.8538e-01, -1.5085e-01, -1.1430e+00,  1.1163e+00,\n",
      "        -1.6534e+00, -1.1215e+00, -1.8885e+00, -2.3102e+00,  1.8395e+00,\n",
      "        -1.4072e+00, -2.8119e+00, -3.3014e+00, -5.4583e-01,  5.3575e-01,\n",
      "        -3.3550e+00, -1.9394e+00, -1.4369e+00, -2.0799e+00,  1.0298e+00,\n",
      "         7.6606e-01, -1.7189e+00, -4.3531e-02, -2.6271e+00,  7.4904e+00,\n",
      "         8.7529e-01,  1.5082e+00, -3.0841e+00, -1.3444e+00, -3.1554e+00,\n",
      "        -1.4641e+00, -4.1890e+00,  2.8284e-01, -4.0142e-01,  5.8519e-01,\n",
      "        -9.6306e-02, -1.5788e+00, -2.4649e+00,  7.9057e-01,  6.7724e-01,\n",
      "        -1.0712e+00, -6.7547e-01,  4.1097e-01, -1.3468e-01,  3.1050e-01,\n",
      "        -3.1523e-01, -9.3057e-01,  2.4811e+00, -4.2663e-01,  1.2861e+00,\n",
      "        -3.9774e-01, -1.6067e+00,  7.3882e-02, -2.9237e+00, -5.5623e-01,\n",
      "        -2.0783e-01, -7.8810e-01, -2.7009e+00, -2.7574e+00, -3.4834e+00,\n",
      "        -2.5592e+00, -1.6587e+00, -2.7456e+00, -1.3155e+00,  4.6671e-01,\n",
      "        -1.1093e+00, -6.6570e-01, -2.4061e+00, -2.7735e+00, -1.9285e+00,\n",
      "        -2.2034e+00,  6.0853e+00,  5.6581e+00,  2.8655e+00,  6.4100e+00,\n",
      "         1.2974e+00,  1.3589e+00,  5.7452e+00,  2.7705e+00,  1.2982e+00,\n",
      "         5.8214e-01,  5.3880e-02, -2.9358e-01, -4.7368e-01, -4.2329e-01,\n",
      "        -1.7802e+00, -3.9527e-01, -1.4163e+00, -3.1357e-01,  4.3152e+00,\n",
      "         2.3927e+00, -2.8116e-01, -7.6242e-01,  2.4532e+00,  4.4332e+00,\n",
      "         2.7163e-01,  1.5354e+00,  8.6683e-01, -1.3464e+00,  1.6023e+00,\n",
      "         1.1207e+00, -5.5432e-01,  1.2071e+00, -5.2843e-01,  1.0541e+00,\n",
      "         4.0926e+00,  4.5496e+00,  5.9371e-01,  2.2555e+00,  1.2266e-01,\n",
      "         1.4803e+00, -1.6930e+00,  4.2137e+00,  3.8770e+00,  8.9980e-01,\n",
      "         1.6686e+00, -4.2923e-01, -8.7887e-02, -9.0798e-01,  5.3565e+00,\n",
      "         2.6556e+00,  1.4274e+00,  2.3591e-01,  6.5906e+00,  2.1124e+00,\n",
      "         1.3018e+00, -8.8185e-01,  4.6874e+00,  2.4550e+00, -1.7623e-01,\n",
      "        -2.0454e+00,  1.9276e-01,  2.9354e+00,  1.1430e+00,  8.7655e-01,\n",
      "         2.1812e+00,  3.7016e+00,  2.3891e+00,  2.0640e+00,  5.9695e-01,\n",
      "         1.7928e+00, -1.5818e+00,  7.0992e+00,  5.5427e+00,  7.2015e+00,\n",
      "         2.1539e+00,  2.3155e+00,  4.3141e+00,  3.6316e+00,  2.9590e+00,\n",
      "         5.3013e+00,  7.2519e+00,  6.8848e+00,  6.9810e-01,  6.9717e-01,\n",
      "         6.2982e+00,  1.9783e+00,  8.9455e-01,  4.3720e-01,  1.6732e+00,\n",
      "         2.6122e+00,  1.3918e+00,  9.9787e-01, -3.1327e-01,  3.3182e+00,\n",
      "         9.5835e-01,  6.0793e-01,  3.4678e+00,  8.2230e+00,  6.4206e+00,\n",
      "         6.4243e+00,  1.7845e+00,  2.4306e-01,  1.7204e+00,  1.1965e+00,\n",
      "         2.8093e+00,  4.3926e+00,  8.2000e+00,  1.2776e+01,  9.4135e+00,\n",
      "         6.8797e+00,  8.4079e+00,  1.8012e+00,  4.6654e+00,  4.5297e+00,\n",
      "         2.6417e+00,  1.2802e+00,  2.7984e+00, -5.8052e-01,  4.8921e+00,\n",
      "         8.9825e+00,  1.5337e+00,  2.3591e+00,  4.2308e+00,  5.0354e+00,\n",
      "        -8.8467e-01,  4.4582e-01,  3.0862e+00,  2.4934e+00,  7.1393e+00,\n",
      "         2.6510e+00,  2.9643e+00,  1.3999e+00,  6.5207e+00,  3.1288e+00,\n",
      "         3.5729e+00,  2.3105e-01,  3.2757e+00,  4.3981e-01,  1.1972e+00,\n",
      "        -1.5733e-01,  2.3810e+00,  1.7232e+00,  1.4009e+00, -7.5995e-02,\n",
      "        -1.6510e-01,  1.0521e+00, -1.0927e+00, -1.2375e+00, -1.2289e-01,\n",
      "        -2.1614e+00, -2.8592e+00, -1.3245e+00, -1.5155e+00, -1.6582e+00,\n",
      "        -2.1023e+00,  3.8612e-01, -9.3121e-01, -3.2139e+00, -7.1650e-01,\n",
      "        -3.7237e-01, -2.6560e+00, -1.4305e+00, -6.7720e-01,  6.4707e-01,\n",
      "        -2.5702e+00, -2.6687e+00, -2.4140e+00, -2.9279e+00, -3.4107e+00,\n",
      "        -1.8254e+00, -1.7090e+00, -3.2740e+00, -1.9872e+00, -8.2992e-01,\n",
      "        -4.7262e-01, -1.6200e+00, -1.1185e-01, -6.9124e-01, -1.8316e+00,\n",
      "         2.5827e+00,  5.3910e+00,  6.3939e+00,  2.8635e+00,  6.2333e-02,\n",
      "         9.9880e-01,  1.5260e-01, -7.5345e-01,  9.0768e-01,  1.6450e+00,\n",
      "        -7.2268e-02,  4.1942e-01, -6.7981e-01, -1.1968e+00, -1.8703e+00,\n",
      "         5.5378e-01, -5.0973e-01, -4.9192e-01,  2.0944e+00, -9.9584e-01,\n",
      "        -6.5534e-01, -1.7752e+00, -2.8813e-01,  1.2089e+00, -9.3352e-02,\n",
      "         4.6972e+00,  1.1818e+00,  9.1299e-01,  2.6384e+00,  1.9745e+00,\n",
      "        -1.5490e+00,  2.4318e+00, -5.3895e-01,  8.9282e-01, -1.2548e+00,\n",
      "        -1.2543e+00, -1.5293e+00, -1.5750e+00,  1.1924e+00, -7.0071e-01,\n",
      "        -9.0333e-01,  2.5048e-01, -1.2197e+00,  2.8932e+00, -4.3679e-01,\n",
      "        -1.6542e+00, -3.1202e+00,  6.5742e-01, -7.7794e-01, -5.4016e-01,\n",
      "         1.2312e-01, -1.0704e-02,  4.6764e-01,  4.0133e-01,  1.3335e+00,\n",
      "        -2.3655e+00, -3.9917e+00, -4.9446e-02,  4.8721e-01, -5.5492e-01,\n",
      "        -1.4285e+00, -5.2597e-02, -2.9994e+00, -3.6115e+00, -1.3414e+00,\n",
      "        -2.1964e+00, -2.1170e+00, -2.6896e+00, -3.6692e-01, -1.0170e+00,\n",
      "        -7.5116e-01,  1.1248e-01, -1.8013e+00, -2.7270e+00, -3.8507e+00,\n",
      "         2.5915e-01, -6.5887e-01, -1.7527e+00,  1.6724e+00,  1.3808e+00,\n",
      "        -1.7875e+00, -5.2237e-01,  1.4458e+00, -4.0817e-01, -3.4951e-01,\n",
      "        -1.5230e+00, -2.3686e+00,  3.0946e-01, -3.3409e-01,  1.6091e-01,\n",
      "         1.2283e-01,  2.8469e-02, -1.7153e-01, -3.1001e+00, -3.9549e+00,\n",
      "         3.1136e-01,  5.2227e-01,  3.7792e-01,  1.9123e+00,  2.2481e+00,\n",
      "        -8.3737e-01, -1.5906e+00, -1.7494e+00, -1.8328e+00, -1.3967e+00,\n",
      "         6.4678e-01,  7.6698e-01, -4.0637e-01, -1.8445e+00,  2.0532e+00,\n",
      "        -1.1728e+00, -2.1554e+00,  3.8815e-01, -2.8968e+00, -8.5392e-02,\n",
      "         8.2068e-01, -1.2280e+00, -7.7474e-01, -9.8572e-01, -1.3277e-01,\n",
      "         3.2557e-01, -1.6146e+00,  1.8050e+00, -1.8929e-01, -5.2596e-01,\n",
      "        -5.6798e-02,  5.7347e-01,  2.1511e+00,  1.0767e+00, -2.9967e-01,\n",
      "         4.0441e-01, -2.8609e-01,  1.3579e+00,  2.4750e+00, -1.0867e+00,\n",
      "        -1.3409e-01, -2.5699e+00, -2.1994e+00,  5.5765e-01,  1.8525e+00,\n",
      "         1.2453e+00,  8.1211e-01,  1.7169e+00, -2.6563e+00, -1.2311e+00,\n",
      "        -5.0834e-01,  4.1962e-02, -7.0224e-01,  2.1241e+00,  3.1355e+00,\n",
      "         4.9690e-01, -3.9939e-01, -1.1610e+00,  2.6060e-01, -1.5735e+00,\n",
      "         2.9393e-01, -1.3264e+00,  6.7074e-01,  2.0427e+00,  8.9492e-01,\n",
      "        -1.3691e+00, -9.0066e-01, -1.2307e+00, -8.5907e-01, -8.2648e-01,\n",
      "        -7.2416e-01, -4.3816e-01, -2.3585e-01, -2.2333e+00, -9.6212e-01,\n",
      "        -3.4820e+00,  1.2806e+00,  6.1824e-01, -1.5795e+00, -1.0051e+00,\n",
      "        -9.7119e-01, -1.6972e-02,  4.4361e-01,  9.7902e-01, -2.1455e+00,\n",
      "        -1.0818e+00,  1.8672e+00,  1.0465e-01, -1.1177e+00, -1.0788e+00,\n",
      "         5.7788e-01, -1.1466e+00, -5.1757e-01,  3.0133e-01,  5.9978e-01,\n",
      "        -1.7518e+00,  1.0528e-01,  3.3727e+00,  6.6370e-01, -7.3170e-01,\n",
      "        -1.1157e+00, -1.0760e+00, -1.7645e-01,  1.6160e+00, -5.1676e-01,\n",
      "        -3.7355e-02, -6.5958e-01, -5.1048e-01, -1.5785e+00,  2.0827e-01,\n",
      "         3.6543e-01, -1.5673e+00,  2.5849e+00, -1.3525e+00,  2.3743e+00,\n",
      "        -2.0301e+00, -3.6402e-01, -7.4326e-01, -2.0588e-01,  2.2687e+00,\n",
      "        -1.0287e+00, -1.0464e+00, -5.5536e+00, -1.0947e+00, -2.2432e+00,\n",
      "        -2.2467e+00, -9.7576e-01,  1.7677e+00,  4.8652e-01,  1.4647e-01,\n",
      "        -1.0163e+00, -7.1231e-01,  8.3915e-01, -7.2118e-01,  1.6299e-01,\n",
      "         2.1676e+00,  3.3834e-01, -3.7376e-01, -2.7165e-01, -6.6897e-01,\n",
      "        -1.8339e+00,  1.2424e-01, -1.9148e-01,  2.1828e+00, -5.7099e-02,\n",
      "        -1.3597e+00, -1.7828e+00,  1.2700e+00, -3.7810e-01,  4.6466e+00,\n",
      "         1.5633e+00,  5.4555e-01, -5.3486e-01,  1.6533e+00, -3.6282e-01,\n",
      "         1.2511e+00,  8.7247e-01, -7.2255e-02, -7.4673e-01, -1.2112e+00,\n",
      "        -2.4617e+00,  5.7479e-01,  1.0272e-01, -3.0034e-01, -1.8553e+00,\n",
      "         3.8384e-01,  7.0100e-01, -6.4588e-01, -7.8294e-01,  5.8508e-01,\n",
      "        -7.2640e-01,  2.1400e+00,  2.3116e-01, -1.0434e+00, -2.0175e+00,\n",
      "         4.0911e-01,  6.1559e-01, -2.0256e-01,  1.2906e-01, -1.5174e-01,\n",
      "        -1.5231e+00,  3.7640e-01,  9.1887e-01, -1.1127e-01, -1.7229e+00,\n",
      "        -2.5250e+00, -1.2399e+00, -1.6609e+00, -4.9534e-02,  8.9906e-01,\n",
      "        -1.4543e+00, -6.2979e-02, -9.4104e-01,  1.3903e+00, -1.5849e+00,\n",
      "        -7.5423e-01,  3.4552e+00,  2.0644e+00,  2.5948e-01, -1.1030e+00,\n",
      "        -8.9831e-01, -1.5546e-01,  3.6403e-01, -1.8181e+00,  1.0744e+00,\n",
      "         1.6060e+00,  9.4678e-02, -2.3046e-01,  4.0993e-02, -2.1912e+00,\n",
      "         7.9663e-01,  2.6189e-01,  2.3826e+00, -9.2375e-01, -1.7903e+00,\n",
      "         1.2551e-01, -5.4314e-01, -1.9375e+00,  4.4195e-01,  1.8747e+00,\n",
      "        -6.8337e-01,  2.7900e+00, -2.2576e+00, -1.9741e+00, -8.3866e-01,\n",
      "        -1.0927e+00, -2.3664e+00,  4.1462e-01,  1.4248e-01, -1.7995e+00,\n",
      "        -2.7896e-01,  1.2172e+00,  1.0992e+00, -1.8520e-01,  2.9030e-01,\n",
      "         5.7806e-01, -6.8574e-01,  8.7389e-02, -1.5035e+00,  1.3086e+00,\n",
      "         1.1546e+00,  1.1846e-01,  2.0439e+00, -1.2885e+00, -1.9019e+00,\n",
      "         8.0995e-01,  4.1087e-02,  1.4980e-01,  2.8706e-01,  4.6107e-01,\n",
      "        -4.5139e-01,  4.1344e+00, -5.2124e-01, -1.3821e+00, -1.5423e-02,\n",
      "        -2.0235e-01,  1.9055e+00, -1.0010e+00, -2.0046e+00, -1.2056e+00,\n",
      "         2.9031e-01, -2.1070e+00, -2.1326e+00, -4.9003e-01, -7.9553e-01,\n",
      "        -1.0346e+00, -1.9397e+00, -6.8290e-02,  4.9958e-01, -7.7605e-02,\n",
      "         1.8082e-01, -2.1652e-01, -1.7763e+00,  6.2266e-01, -3.4899e-01,\n",
      "         1.5236e+00, -1.0410e+00, -2.5923e+00,  1.2085e+00, -7.9445e-01,\n",
      "        -2.2573e+00, -1.1834e-01,  2.3174e-01,  9.4567e-01, -1.8829e+00,\n",
      "        -2.3556e+00,  1.3470e+00,  6.4159e-01, -7.2930e-01, -8.8545e-01,\n",
      "        -2.7610e+00,  1.8733e+00, -2.0879e-01,  1.1911e-01,  8.1170e-01,\n",
      "        -7.9686e-01, -9.0680e-01,  1.7048e+00,  1.3574e+00, -1.1055e+00,\n",
      "        -7.4800e-01, -4.5787e+00, -1.0399e+00,  6.1047e-01, -2.2398e+00,\n",
      "        -9.3784e-03,  1.4005e+00, -1.3131e+00,  9.6400e-02, -1.9672e+00,\n",
      "        -2.6771e-01, -1.9140e+00, -1.9674e+00, -3.9607e-01, -4.0739e+00,\n",
      "        -7.0035e-01, -6.7019e-01,  1.0259e+00, -1.8295e+00,  4.9275e-01,\n",
      "        -2.1938e+00,  8.5932e-01, -1.5164e+00,  2.1868e+00,  1.0053e+00,\n",
      "         1.1587e+00,  1.2329e+00,  9.4269e-01, -5.4513e-01,  1.1483e+00,\n",
      "         9.9737e-01,  1.9728e+00, -7.9368e-01, -1.5064e-01, -3.9933e-01,\n",
      "        -4.7156e-01,  2.3797e+00, -1.3125e+00, -4.1223e-01,  5.8889e-01,\n",
      "         1.1337e+00,  2.4878e-01, -1.4671e+00,  3.1672e+00, -3.3441e-01,\n",
      "         3.5220e-01,  1.5297e+00,  6.5348e-01, -7.9813e-01, -1.4292e+00,\n",
      "        -1.7508e+00, -1.3396e+00, -1.8549e+00,  1.3376e+00, -2.8279e+00,\n",
      "        -8.4971e-01, -4.5904e-01,  9.7757e-01,  1.1362e+00,  2.3635e-01,\n",
      "        -4.8809e-01, -1.0056e+00,  1.7697e+00,  4.3906e-02, -2.0320e-01,\n",
      "         4.5244e-01,  2.2109e-01,  2.3199e+00, -8.9795e-01, -2.4936e+00,\n",
      "        -1.8956e+00, -1.9415e+00,  4.3283e-02, -1.4917e+00, -1.8406e-01,\n",
      "        -1.0562e+00, -1.8524e+00,  6.0727e-01, -2.7266e+00, -1.0466e+00,\n",
      "         3.5877e+00, -6.2127e-01,  5.7452e-01, -4.4227e-01, -6.0068e-02,\n",
      "         4.8726e-01,  4.8826e-01, -2.4690e+00,  4.1191e-01,  1.0732e+00,\n",
      "         9.3909e-01, -1.0708e+00,  2.2816e+00,  4.4190e-01, -1.2598e+00,\n",
      "        -4.7484e-01, -1.3660e+00, -4.9099e-01, -2.8423e-01,  2.2655e-01,\n",
      "        -1.0871e-01,  3.9156e+00,  5.6616e-01,  1.0714e-01, -2.7578e+00,\n",
      "        -2.1005e+00, -1.8217e-01, -2.1068e-01, -1.0794e+00,  6.3908e-01,\n",
      "         6.0117e-01,  6.8416e-01,  1.8310e+00,  4.7238e-01, -1.0757e+00,\n",
      "        -4.3509e-01, -5.9589e-01, -1.0432e+00,  1.6481e+00,  4.1502e-01,\n",
      "         1.5491e-01, -1.4294e+00, -3.2228e-01, -3.8464e-01, -3.4619e-01,\n",
      "         1.3294e+00,  4.9685e-01,  4.7617e+00, -1.4655e+00, -9.3554e-01,\n",
      "        -2.5451e-01, -1.8215e+00, -1.2040e+00, -5.4667e-01, -2.0594e+00,\n",
      "        -8.9480e-01, -3.7502e-01,  1.8928e-01, -2.1615e+00,  6.8265e-01,\n",
      "         6.6691e-01, -2.3398e-01,  1.5941e+00, -2.8771e-01,  8.4578e-01,\n",
      "         1.0385e+00, -1.6923e-01, -3.8572e-01, -4.6882e-02, -3.8097e+00,\n",
      "        -6.6123e-01,  2.0870e+00, -2.1004e+00,  5.3965e-01,  1.5145e+00,\n",
      "         1.9913e+00, -1.0415e+00,  8.1989e-01, -1.5048e+00, -1.1611e+00,\n",
      "        -1.2903e+00, -5.0271e-01, -3.4022e+00, -1.3990e+00, -1.1075e+00,\n",
      "        -1.5195e+00, -8.1167e-01, -6.1630e-03, -1.6215e+00, -1.6200e+00,\n",
      "        -3.1629e+00, -2.1399e-04, -4.6137e-01, -2.0681e-01, -7.8552e-01,\n",
      "        -1.9155e-01, -1.6744e+00,  1.4653e+00, -6.4916e-01,  6.6898e-01,\n",
      "        -2.8261e-01, -1.7052e+00, -4.2775e-01, -1.9692e+00,  6.4841e-01,\n",
      "         2.1865e-01, -5.8163e-01,  2.6314e+00, -8.7590e-01, -8.4983e-01,\n",
      "        -3.5468e-01, -9.7867e-02, -1.6981e+00, -7.9244e-01, -4.9086e-01,\n",
      "        -1.9652e+00, -4.5403e-01, -1.9348e+00, -1.4982e-02, -9.1651e-01,\n",
      "        -1.0795e+00, -1.4098e+00, -9.4895e-01, -1.6395e+00,  2.4803e+00,\n",
      "        -8.9321e-01, -1.1523e+00, -6.2899e-01, -2.5171e+00, -4.4567e-01,\n",
      "         7.2549e-01, -7.0211e-01,  2.7455e+00,  2.0548e+00, -1.4174e-01,\n",
      "        -1.4292e+00, -1.0815e+00, -1.6127e+00,  9.2056e-01,  1.1905e-01,\n",
      "        -6.7013e-01, -4.8398e-02, -7.9915e-01,  1.7239e+00,  1.6167e+00,\n",
      "         2.9594e-01, -1.2275e-01, -8.3370e-01, -2.8104e-01,  1.3021e-01,\n",
      "        -1.3819e+00,  1.4736e+00,  2.3947e+00,  1.1290e+00, -1.7542e-02,\n",
      "        -1.8492e+00, -8.5648e-01, -7.4951e-01, -6.0788e-01, -1.6082e+00,\n",
      "        -2.4531e+00,  1.1408e+00, -1.5267e+00,  1.0321e+00,  2.0267e-01,\n",
      "        -1.2123e-02,  2.8846e+00, -7.2888e-01, -3.1148e+00, -1.3770e+00,\n",
      "         2.1375e+00, -1.5760e+00,  5.8303e-01, -7.7441e-01,  4.9826e-01,\n",
      "         1.5099e-01, -2.9591e-02,  8.7164e-01, -1.8424e+00, -1.1896e+00,\n",
      "        -8.2445e-01,  1.2416e+00,  1.3307e+00,  1.3703e-01, -5.1208e-01,\n",
      "         2.1070e+00, -5.7916e-01, -2.6201e-01, -3.3853e+00, -1.1297e+00,\n",
      "        -5.9502e-01, -1.4694e+00, -1.9768e+00,  2.4667e-01, -4.3579e-01])\n",
      "tensor([2.2477e-06, 5.7400e-07, 7.9565e-07, 4.7353e-07, 1.4483e-07, 3.1733e-06,\n",
      "        8.5920e-07, 5.1084e-05, 3.1556e-04, 2.8510e-06, 1.2210e-07, 7.2552e-07,\n",
      "        4.1613e-07, 1.8176e-07, 1.5905e-07, 4.7587e-07, 1.3131e-06, 8.2814e-06,\n",
      "        2.1882e-06, 8.3071e-07, 3.3004e-07, 1.3086e-06, 1.4239e-06, 7.6416e-06,\n",
      "        4.1103e-07, 1.5671e-06, 1.3381e-06, 1.3068e-06, 8.8368e-07, 7.5265e-06,\n",
      "        7.5759e-07, 9.7183e-07, 1.2716e-06, 1.3984e-07, 2.5436e-07, 7.6369e-07,\n",
      "        7.4310e-07, 5.0083e-07, 1.4653e-07, 1.3704e-06, 1.6676e-06, 1.8347e-07,\n",
      "        5.1056e-07, 1.9160e-07, 4.4136e-06, 2.9145e-07, 1.4549e-06, 5.4293e-07,\n",
      "        2.0363e-07, 7.9109e-07, 2.9179e-06, 1.5745e-06, 2.9114e-06, 3.2598e-06,\n",
      "        7.5408e-07, 9.5602e-07, 6.9310e-07, 9.6028e-07, 1.4572e-06, 1.4425e-06,\n",
      "        1.1160e-05, 5.0048e-07, 2.2334e-07, 5.2380e-07, 1.1736e-07, 3.0964e-07,\n",
      "        1.0006e-06, 9.2338e-07, 8.0743e-07, 2.9008e-08, 9.9102e-07, 3.0449e-06,\n",
      "        9.7636e-07, 6.3146e-07, 3.0023e-06, 3.5149e-07, 4.8064e-07, 1.8626e-06,\n",
      "        7.9632e-06, 1.2757e-06, 6.1712e-07, 2.0525e-06, 2.1246e-06, 7.8778e-07,\n",
      "        7.5442e-06, 4.7284e-07, 8.0486e-07, 3.7378e-07, 2.4519e-07, 1.5549e-05,\n",
      "        6.0483e-07, 1.4846e-07, 9.0998e-08, 1.4313e-06, 4.2215e-06, 8.6242e-08,\n",
      "        3.5526e-07, 5.8716e-07, 3.0866e-07, 6.9188e-06, 5.3148e-06, 4.4286e-07,\n",
      "        2.3653e-06, 1.7859e-07, 4.4242e-03, 5.9283e-06, 1.1163e-05, 1.1308e-07,\n",
      "        6.4403e-07, 1.0530e-07, 5.7140e-07, 3.7455e-08, 3.2782e-06, 1.6537e-06,\n",
      "        4.4355e-06, 2.2437e-06, 5.0947e-07, 2.1004e-07, 5.4467e-06, 4.8631e-06,\n",
      "        8.4640e-07, 1.2573e-06, 3.7263e-06, 2.1592e-06, 3.3701e-06, 1.8026e-06,\n",
      "        9.7421e-07, 2.9534e-05, 1.6125e-06, 8.9403e-06, 1.6598e-06, 4.9547e-07,\n",
      "        2.6600e-06, 1.3276e-07, 1.4165e-06, 2.0069e-06, 1.1234e-06, 1.6589e-07,\n",
      "        1.5677e-07, 7.5852e-08, 1.9113e-07, 4.7034e-07, 1.5863e-07, 6.6292e-07,\n",
      "        3.9399e-06, 8.1475e-07, 1.2696e-06, 2.2275e-07, 1.5427e-07, 3.5914e-07,\n",
      "        2.7282e-07, 1.0855e-03, 7.0805e-04, 4.3377e-05, 1.5019e-03, 9.0415e-06,\n",
      "        9.6149e-06, 7.7250e-04, 3.9444e-05, 9.0486e-06, 4.4220e-06, 2.6073e-06,\n",
      "        1.8420e-06, 1.5384e-06, 1.6179e-06, 4.1656e-07, 1.6639e-06, 5.9937e-07,\n",
      "        1.8056e-06, 1.8487e-04, 2.7035e-05, 1.8650e-06, 1.1526e-06, 2.8720e-05,\n",
      "        2.0803e-04, 3.2416e-06, 1.1471e-05, 5.8783e-06, 6.4276e-07, 1.2264e-05,\n",
      "        7.5772e-06, 1.4192e-06, 8.2607e-06, 1.4565e-06, 7.0890e-06, 1.4797e-04,\n",
      "        2.3369e-04, 4.4734e-06, 2.3570e-05, 2.7930e-06, 1.0856e-05, 4.5450e-07,\n",
      "        1.6702e-04, 1.1927e-04, 6.0754e-06, 1.3105e-05, 1.6083e-06, 2.2627e-06,\n",
      "        9.9647e-07, 5.2370e-04, 3.5166e-05, 1.0297e-05, 3.1279e-06, 1.7990e-03,\n",
      "        2.0426e-05, 9.0818e-06, 1.0228e-06, 2.6823e-04, 2.8772e-05, 2.0714e-06,\n",
      "        3.1951e-07, 2.9958e-06, 4.6519e-05, 7.7477e-06, 5.9357e-06, 2.1882e-05,\n",
      "        1.0008e-04, 2.6937e-05, 1.9462e-05, 4.4879e-06, 1.4839e-05, 5.0793e-07,\n",
      "        2.9918e-03, 6.3089e-04, 3.3143e-03, 2.1292e-05, 2.5027e-05, 1.8467e-04,\n",
      "        9.3317e-05, 4.7631e-05, 4.9561e-04, 3.4855e-03, 2.4145e-03, 4.9656e-06,\n",
      "        4.9610e-06, 1.3429e-03, 1.7864e-05, 6.0436e-06, 3.8253e-06, 1.3166e-05,\n",
      "        3.3672e-05, 9.9368e-06, 6.7014e-06, 1.8061e-06, 6.8210e-05, 6.4417e-06,\n",
      "        4.5375e-06, 7.9221e-05, 9.2043e-03, 1.5179e-03, 1.5234e-03, 1.4716e-05,\n",
      "        3.1503e-06, 1.3802e-05, 8.1735e-06, 4.1006e-05, 1.9974e-04, 8.9950e-03,\n",
      "        8.7330e-01, 3.0271e-02, 2.4023e-03, 1.1074e-02, 1.4964e-05, 2.6240e-04,\n",
      "        2.2909e-04, 3.4680e-05, 8.8872e-06, 4.0564e-05, 1.3825e-06, 3.2916e-04,\n",
      "        1.9671e-02, 1.1452e-05, 2.6143e-05, 1.6991e-04, 3.7986e-04, 1.0200e-06,\n",
      "        3.8584e-06, 5.4092e-05, 2.9899e-05, 3.1142e-03, 3.5004e-05, 4.7882e-05,\n",
      "        1.0017e-05, 1.6776e-03, 5.6445e-05, 8.8002e-05, 3.1127e-06, 6.5376e-05,\n",
      "        3.8353e-06, 8.1796e-06, 2.1109e-06, 2.6721e-05, 1.3841e-05, 1.0028e-05,\n",
      "        2.2898e-06, 2.0946e-06, 7.0745e-06, 8.2841e-07, 7.1670e-07, 2.1849e-06,\n",
      "        2.8453e-07, 1.4160e-07, 6.5699e-07, 5.4277e-07, 4.7062e-07, 3.0185e-07,\n",
      "        3.6348e-06, 9.7359e-07, 9.9318e-08, 1.2068e-06, 1.7025e-06, 1.7350e-07,\n",
      "        5.9092e-07, 1.2551e-06, 4.7186e-06, 1.8904e-07, 1.7132e-07, 2.2101e-07,\n",
      "        1.3220e-07, 8.1572e-08, 3.9815e-07, 4.4729e-07, 9.3518e-08, 3.3867e-07,\n",
      "        1.0774e-06, 1.5401e-06, 4.8893e-07, 2.2091e-06, 1.2376e-06, 3.9567e-07,\n",
      "        3.2692e-05, 5.4211e-04, 1.4778e-03, 4.3290e-05, 2.6294e-06, 6.7076e-06,\n",
      "        2.8779e-06, 1.1630e-06, 6.1234e-06, 1.2800e-05, 2.2983e-06, 3.7579e-06,\n",
      "        1.2519e-06, 7.4649e-07, 3.8066e-07, 4.2983e-06, 1.4839e-06, 1.5106e-06,\n",
      "        2.0062e-05, 9.1265e-07, 1.2829e-06, 4.1864e-07, 1.8521e-06, 8.2755e-06,\n",
      "        2.2504e-06, 2.7088e-04, 8.0544e-06, 6.1560e-06, 3.4565e-05, 1.7795e-05,\n",
      "        5.2488e-07, 2.8112e-05, 1.4412e-06, 6.0331e-06, 7.0446e-07, 7.0477e-07,\n",
      "        5.3532e-07, 5.1143e-07, 8.1405e-06, 1.2260e-06, 1.0011e-06, 3.1738e-06,\n",
      "        7.2959e-07, 4.4596e-05, 1.5962e-06, 4.7247e-07, 1.0907e-07, 4.7677e-06,\n",
      "        1.1349e-06, 1.4395e-06, 2.7942e-06, 2.4442e-06, 3.9436e-06, 3.6905e-06,\n",
      "        9.3743e-06, 2.3198e-07, 4.5627e-08, 2.3514e-06, 4.0215e-06, 1.4184e-06,\n",
      "        5.9213e-07, 2.3440e-06, 1.2308e-07, 6.6736e-08, 6.4602e-07, 2.7472e-07,\n",
      "        2.9744e-07, 1.6777e-07, 1.7118e-06, 8.9353e-07, 1.1656e-06, 2.7647e-06,\n",
      "        4.0785e-07, 1.6161e-07, 5.2534e-08, 3.2014e-06, 1.2783e-06, 4.2817e-07,\n",
      "        1.3155e-05, 9.8284e-06, 4.1353e-07, 1.4653e-06, 1.0489e-05, 1.6426e-06,\n",
      "        1.7418e-06, 5.3870e-07, 2.3128e-07, 3.3666e-06, 1.7689e-06, 2.9019e-06,\n",
      "        2.7934e-06, 2.5419e-06, 2.0811e-06, 1.1128e-07, 4.7339e-08, 3.3730e-06,\n",
      "        4.1650e-06, 3.6051e-06, 1.6723e-05, 2.3394e-05, 1.0694e-06, 5.0351e-07,\n",
      "        4.2956e-07, 3.9520e-07, 6.1126e-07, 4.7172e-06, 5.3197e-06, 1.6455e-06,\n",
      "        3.9059e-07, 1.9252e-05, 7.6465e-07, 2.8622e-07, 3.6422e-06, 1.3637e-07,\n",
      "        2.2683e-06, 5.6132e-06, 7.2357e-07, 1.1385e-06, 9.2193e-07, 2.1634e-06,\n",
      "        3.4213e-06, 4.9158e-07, 1.5020e-05, 2.0445e-06, 1.4601e-06, 2.3341e-06,\n",
      "        4.3838e-06, 2.1232e-05, 7.2513e-06, 1.8308e-06, 3.7019e-06, 1.8559e-06,\n",
      "        9.6052e-06, 2.9354e-05, 8.3335e-07, 2.1605e-06, 1.8911e-07, 2.7392e-07,\n",
      "        4.3150e-06, 1.5751e-05, 8.5827e-06, 5.5653e-06, 1.3754e-05, 1.7345e-07,\n",
      "        7.2134e-07, 1.4860e-06, 2.5764e-06, 1.2241e-06, 2.0667e-05, 5.6823e-05,\n",
      "        4.0606e-06, 1.6571e-06, 7.7374e-07, 3.2060e-06, 5.1220e-07, 3.3147e-06,\n",
      "        6.5576e-07, 4.8316e-06, 1.9052e-05, 6.0458e-06, 6.2834e-07, 1.0038e-06,\n",
      "        7.2160e-07, 1.0464e-06, 1.0811e-06, 1.1976e-06, 1.5941e-06, 1.9515e-06,\n",
      "        2.6477e-07, 9.4396e-07, 7.5957e-08, 8.8909e-06, 4.5845e-06, 5.0915e-07,\n",
      "        9.0425e-07, 9.3543e-07, 2.4290e-06, 3.8499e-06, 6.5762e-06, 2.8909e-07,\n",
      "        8.3746e-07, 1.5984e-05, 2.7431e-06, 8.0796e-07, 8.3998e-07, 4.4032e-06,\n",
      "        7.8495e-07, 1.4724e-06, 3.3393e-06, 4.5007e-06, 4.2854e-07, 2.7448e-06,\n",
      "        7.2037e-05, 4.7977e-06, 1.1886e-06, 8.0954e-07, 8.4232e-07, 2.0709e-06,\n",
      "        1.2434e-05, 1.4736e-06, 2.3800e-06, 1.2774e-06, 1.4828e-06, 5.0964e-07,\n",
      "        3.0426e-06, 3.5604e-06, 5.1538e-07, 3.2763e-05, 6.3889e-07, 2.6542e-05,\n",
      "        3.2444e-07, 1.7167e-06, 1.1749e-06, 2.0109e-06, 2.3883e-05, 8.8314e-07,\n",
      "        8.6768e-07, 9.5697e-09, 8.2671e-07, 2.6216e-07, 2.6125e-07, 9.3117e-07,\n",
      "        1.4471e-05, 4.0187e-06, 2.8603e-06, 8.9419e-07, 1.2118e-06, 5.7178e-06,\n",
      "        1.2011e-06, 2.9079e-06, 2.1585e-05, 3.4652e-06, 1.7001e-06, 1.8829e-06,\n",
      "        1.2655e-06, 3.9476e-07, 2.7974e-06, 2.0400e-06, 2.1916e-05, 2.3334e-06,\n",
      "        6.3428e-07, 4.1547e-07, 8.7970e-06, 1.6927e-06, 2.5752e-04, 1.1796e-05,\n",
      "        4.2631e-06, 1.4471e-06, 1.2907e-05, 1.7188e-06, 8.6321e-06, 5.9116e-06,\n",
      "        2.2983e-06, 1.1708e-06, 7.3581e-07, 2.1071e-07, 4.3896e-06, 2.7378e-06,\n",
      "        1.8296e-06, 3.8640e-07, 3.6266e-06, 4.9800e-06, 1.2951e-06, 1.1292e-06,\n",
      "        4.4350e-06, 1.1949e-06, 2.0998e-05, 3.1131e-06, 8.7022e-07, 3.2856e-07,\n",
      "        3.7194e-06, 4.5724e-06, 2.0176e-06, 2.8109e-06, 2.1227e-06, 5.3866e-07,\n",
      "        3.5996e-06, 6.1924e-06, 2.2104e-06, 4.4110e-07, 1.9779e-07, 7.1499e-07,\n",
      "        4.6932e-07, 2.3512e-06, 6.0708e-06, 5.7703e-07, 2.3198e-06, 9.6406e-07,\n",
      "        9.9223e-06, 5.0639e-07, 1.1621e-06, 7.8228e-05, 1.9470e-05, 3.2025e-06,\n",
      "        8.1992e-07, 1.0062e-06, 2.1148e-06, 3.5554e-06, 4.0105e-07, 7.2340e-06,\n",
      "        1.2311e-05, 2.7159e-06, 1.9620e-06, 2.5739e-06, 2.7616e-07, 5.4798e-06,\n",
      "        3.2102e-06, 2.6763e-05, 9.8087e-07, 4.1235e-07, 2.8009e-06, 1.4352e-06,\n",
      "        3.5593e-07, 3.8435e-06, 1.6106e-05, 1.2474e-06, 4.0224e-05, 2.5842e-07,\n",
      "        3.4312e-07, 1.0680e-06, 8.2840e-07, 2.3178e-07, 3.7399e-06, 2.8489e-06,\n",
      "        4.0857e-07, 1.8691e-06, 8.3448e-06, 7.4158e-06, 2.0529e-06, 3.3027e-06,\n",
      "        4.4039e-06, 1.2445e-06, 2.6962e-06, 5.4933e-07, 9.1435e-06, 7.8385e-06,\n",
      "        2.7812e-06, 1.9074e-05, 6.8108e-07, 3.6883e-07, 5.5533e-06, 2.5742e-06,\n",
      "        2.8698e-06, 3.2920e-06, 3.9177e-06, 1.5731e-06, 1.5429e-04, 1.4670e-06,\n",
      "        6.2024e-07, 2.4327e-06, 2.0180e-06, 1.6610e-05, 9.0797e-07, 3.3282e-07,\n",
      "        7.3995e-07, 3.3027e-06, 3.0042e-07, 2.9284e-07, 1.5135e-06, 1.1151e-06,\n",
      "        8.7798e-07, 3.5514e-07, 2.3075e-06, 4.0716e-06, 2.2861e-06, 2.9602e-06,\n",
      "        1.9896e-06, 4.1819e-07, 4.6048e-06, 1.7427e-06, 1.1337e-05, 8.7237e-07,\n",
      "        1.8492e-07, 8.2726e-06, 1.1163e-06, 2.5849e-07, 2.1948e-06, 3.1149e-06,\n",
      "        6.3605e-06, 3.7591e-07, 2.3431e-07, 9.5010e-06, 4.6928e-06, 1.1914e-06,\n",
      "        1.0192e-06, 1.5621e-07, 1.6083e-05, 2.0050e-06, 2.7831e-06, 5.5630e-06,\n",
      "        1.1136e-06, 9.9765e-07, 1.3589e-05, 9.6008e-06, 8.1787e-07, 1.1693e-06,\n",
      "        2.5368e-08, 8.7330e-07, 4.5490e-06, 2.6305e-07, 2.4475e-06, 1.0024e-05,\n",
      "        6.6456e-07, 2.7206e-06, 3.4551e-07, 1.8903e-06, 3.6439e-07, 3.4544e-07,\n",
      "        1.6626e-06, 4.2025e-08, 1.2264e-06, 1.2640e-06, 6.8920e-06, 3.9649e-07,\n",
      "        4.0438e-06, 2.7546e-07, 5.8343e-06, 5.4229e-07, 2.2005e-05, 6.7515e-06,\n",
      "        7.8708e-06, 8.4770e-06, 6.3416e-06, 1.4323e-06, 7.7892e-06, 6.6980e-06,\n",
      "        1.7765e-05, 1.1171e-06, 2.1251e-06, 1.6572e-06, 1.5417e-06, 2.6686e-05,\n",
      "        6.6494e-07, 1.6359e-06, 4.4519e-06, 7.6763e-06, 3.1684e-06, 5.6969e-07,\n",
      "        5.8656e-05, 1.7683e-06, 3.5136e-06, 1.1406e-05, 4.7489e-06, 1.1122e-06,\n",
      "        5.9172e-07, 4.2898e-07, 6.4713e-07, 3.8656e-07, 9.4123e-06, 1.4610e-07,\n",
      "        1.0563e-06, 1.5611e-06, 6.5667e-06, 7.6959e-06, 3.1293e-06, 1.5164e-06,\n",
      "        9.0381e-07, 1.4500e-05, 2.5814e-06, 2.0162e-06, 3.8841e-06, 3.0818e-06,\n",
      "        2.5137e-05, 1.0065e-06, 2.0410e-07, 3.7115e-07, 3.5451e-07, 2.5798e-06,\n",
      "        5.5583e-07, 2.0552e-06, 8.5921e-07, 3.8752e-07, 4.5345e-06, 1.6168e-07,\n",
      "        8.6751e-07, 8.9310e-05, 1.3273e-06, 4.3884e-06, 1.5875e-06, 2.3265e-06,\n",
      "        4.0217e-06, 4.0257e-06, 2.0917e-07, 3.7298e-06, 7.2255e-06, 6.3188e-06,\n",
      "        8.4672e-07, 2.4193e-05, 3.8433e-06, 7.0093e-07, 1.5367e-06, 6.3033e-07,\n",
      "        1.5120e-06, 1.8593e-06, 3.0987e-06, 2.2161e-06, 1.2398e-04, 4.3519e-06,\n",
      "        2.7500e-06, 1.5672e-07, 3.0239e-07, 2.0591e-06, 2.0012e-06, 8.3951e-07,\n",
      "        4.6811e-06, 4.5069e-06, 4.8969e-06, 1.5416e-05, 3.9623e-06, 8.4259e-07,\n",
      "        1.5990e-06, 1.3614e-06, 8.7044e-07, 1.2840e-05, 3.7414e-06, 2.8845e-06,\n",
      "        5.9155e-07, 1.7899e-06, 1.6817e-06, 1.7476e-06, 9.3358e-06, 4.0604e-06,\n",
      "        2.8892e-04, 5.7058e-07, 9.6938e-07, 1.9154e-06, 3.9970e-07, 7.4111e-07,\n",
      "        1.4301e-06, 3.1507e-07, 1.0097e-06, 1.6980e-06, 2.9854e-06, 2.8450e-07,\n",
      "        4.8895e-06, 4.8132e-06, 1.9551e-06, 1.2164e-05, 1.8529e-06, 5.7559e-06,\n",
      "        6.9795e-06, 2.0859e-06, 1.6799e-06, 2.3574e-06, 5.4733e-08, 1.2753e-06,\n",
      "        1.9915e-05, 3.0242e-07, 4.2380e-06, 1.1234e-05, 1.8097e-05, 8.7194e-07,\n",
      "        5.6088e-06, 5.4859e-07, 7.7365e-07, 6.7988e-07, 1.4944e-06, 8.2266e-08,\n",
      "        6.0984e-07, 8.1623e-07, 5.4061e-07, 1.0972e-06, 2.4554e-06, 4.8818e-07,\n",
      "        4.8891e-07, 1.0451e-07, 2.4700e-06, 1.5575e-06, 2.0090e-06, 1.1263e-06,\n",
      "        2.0399e-06, 4.6303e-07, 1.0694e-05, 1.2908e-06, 4.8231e-06, 1.8623e-06,\n",
      "        4.4901e-07, 1.6107e-06, 3.4480e-07, 4.7249e-06, 3.0743e-06, 1.3810e-06,\n",
      "        3.4322e-05, 1.0290e-06, 1.0561e-06, 1.7328e-06, 2.2402e-06, 4.5220e-07,\n",
      "        1.1185e-06, 1.5122e-06, 3.4618e-07, 1.5690e-06, 3.5689e-07, 2.4338e-06,\n",
      "        9.8800e-07, 8.3939e-07, 6.0330e-07, 9.5647e-07, 4.7945e-07, 2.9510e-05,\n",
      "        1.0113e-06, 7.8045e-07, 1.3171e-06, 1.9935e-07, 1.5821e-06, 5.1035e-06,\n",
      "        1.2242e-06, 3.8472e-05, 1.9283e-05, 2.1441e-06, 5.9172e-07, 8.3771e-07,\n",
      "        4.9250e-07, 6.2028e-06, 2.7829e-06, 1.2640e-06, 2.3538e-06, 1.1110e-06,\n",
      "        1.3851e-05, 1.2443e-05, 3.3214e-06, 2.1852e-06, 1.0733e-06, 1.8653e-06,\n",
      "        2.8141e-06, 6.2038e-07, 1.0784e-05, 2.7089e-05, 7.6401e-06, 2.4276e-06,\n",
      "        3.8877e-07, 1.0491e-06, 1.1676e-06, 1.3452e-06, 4.9471e-07, 2.1253e-07,\n",
      "        7.7313e-06, 5.3674e-07, 6.9344e-06, 3.0256e-06, 2.4408e-06, 4.4215e-05,\n",
      "        1.1919e-06, 1.0966e-07, 6.2341e-07, 2.0945e-05, 5.1089e-07, 4.4259e-06,\n",
      "        1.1389e-06, 4.0662e-06, 2.8732e-06, 2.3985e-06, 5.9067e-06, 3.9143e-07,\n",
      "        7.5189e-07, 1.0833e-06, 8.5507e-06, 9.3481e-06, 2.8334e-06, 1.4805e-06,\n",
      "        2.0316e-05, 1.3844e-06, 1.9011e-06, 8.3672e-08, 7.9834e-07, 1.3626e-06,\n",
      "        5.6840e-07, 3.4219e-07, 3.1617e-06, 1.5978e-06])\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "print(torch.nn.functional.softmax(output[0], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(258)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
